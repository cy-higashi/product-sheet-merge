import openpyxl
import os
import json
from collections import defaultdict
import re

def analyze_source_file_headers(file_path):
    """
    ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿéš›ã®ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‚’è©³ç´°åˆ†æ
    """
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        ws = wb.active
        max_row = ws.max_row
        max_col = ws.max_column

        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã®å€¤ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼
        data = []
        for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
            data.append([cell.value for cell in row])

        # ã€Œé …ç›®ã€è¡Œã‚’æ¤œç´¢
        header_row_index = None
        for i, row in enumerate(data):
            if len(row) >= 2 and row[1] == "é …ç›®":
                header_row_index = i
                break
        
        if header_row_index is None:
            return None
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¨ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å–å¾—
        header_row = data[header_row_index] if header_row_index < len(data) else []
        sub_header_row = data[header_row_index + 1] if header_row_index + 1 < len(data) else []
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
        sample_data_rows = []
        for row_idx in range(header_row_index + 2, min(header_row_index + 7, len(data))):
            if row_idx < len(data):
                sample_data_rows.append(data[row_idx])
        
        return {
            'file_name': os.path.basename(file_path),
            'header_row_index': header_row_index,
            'header_row': header_row,
            'sub_header_row': sub_header_row,
            'sample_data_rows': sample_data_rows,
            'max_col': max_col
        }
        
    except Exception as e:
        print(f"  âŒ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {file_path} â†’ {e}")
        return None

def detect_semantic_misalignment(source_analysis, integrated_result):
    """
    ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ï¼ˆæ„å‘³çš„ï¼‰ãªåˆ—ã‚ºãƒ¬ã‚’æ¤œå‡º
    """
    misalignments = []
    
    # é‡è¦ãªãƒ‡ãƒ¼ã‚¿å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©
    patterns = {
        'person_name': r'^[ä¸€-é¾¯]{2,4}\s*[ä¸€-é¾¯]{1,3}$',  # æ—¥æœ¬äººåãƒ‘ã‚¿ãƒ¼ãƒ³
        'product_name': r'(è‚‰|ç±³|é‡èœ|æœç‰©|é­š|é…’|èŒ¶|è“å­|ãƒ‘ãƒ³|éºº|èª¿å‘³æ–™)',  # å•†å“åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        'phone_number': r'^\d{2,4}-\d{2,4}-\d{4}$',  # é›»è©±ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³
        'address': r'(å¸‚|ç”º|æ‘|åŒº|çœŒ|éƒ½|åºœ|é“)',  # ä½æ‰€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        'code': r'^[A-Z0-9]{3,10}$',  # ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
        'amount': r'^\d+g$|^\d+ml$|^\d+å€‹$',  # å†…å®¹é‡ãƒ‘ã‚¿ãƒ¼ãƒ³
    }
    
    wb = openpyxl.load_workbook(integrated_result, data_only=True)
    ws = wb.active
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã‚’å–å¾—
    headers = {}
    for col in range(1, ws.max_column + 1):
        header = ws.cell(row=1, column=col).value
        if header:
            headers[col] = str(header)
    
    # é‡è¦ãªåˆ—ã®æœŸå¾…ãƒ‡ãƒ¼ã‚¿å‹ã‚’å®šç¾©
    expected_data_types = {
        'ã”æ‹…å½“è€…æ§˜': 'person_name',
        'å•†å“å': 'product_name',
        'äº‹æ¥­è€…æ§˜TEL': 'phone_number',
        'ç™ºé€å…ƒTEL': 'phone_number',
        'ç™ºé€å…ƒä½æ‰€': 'address',
        'è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰': 'code',
        'å†…å®¹é‡': 'amount'
    }
    
    # å„é‡è¦åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ¤œè¨¼
    for col, header in headers.items():
        # ãƒ˜ãƒƒãƒ€ãƒ¼åãŒæœŸå¾…ãƒ‡ãƒ¼ã‚¿å‹ãƒªã‚¹ãƒˆã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        expected_type = None
        for expected_header, data_type in expected_data_types.items():
            if expected_header in header:
                expected_type = data_type
                break
        
        if expected_type:
            # ã“ã®åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—
            sample_values = []
            for row in range(2, min(50, ws.max_row + 1)):
                value = ws.cell(row=row, column=col).value
                if value and str(value).strip():
                    sample_values.append(str(value).strip())
            
            # ãƒ‡ãƒ¼ã‚¿å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
            pattern = patterns[expected_type]
            mismatched_count = 0
            total_count = len(sample_values)
            
            if total_count > 0:
                for value in sample_values:
                    if not re.match(pattern, value):
                        mismatched_count += 1
                
                mismatch_rate = (mismatched_count / total_count) * 100
                
                if mismatch_rate > 10:  # 10%ä»¥ä¸Šã®ãƒŸã‚¹ãƒãƒƒãƒã§è­¦å‘Š
                    misalignments.append({
                        'column': col,
                        'header': header,
                        'expected_type': expected_type,
                        'mismatch_rate': mismatch_rate,
                        'sample_mismatches': [v for v in sample_values[:5] if not re.match(pattern, v)]
                    })
    
    return misalignments

def cross_validate_with_source_files(base_dir, integrated_result):
    """
    ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ±åˆçµæœã®äº¤å·®æ¤œè¨¼
    """
    # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    files = [f for f in os.listdir(base_dir) 
             if f.startswith("PAT") and f.endswith("_normalized.xlsx") 
             and not f.endswith("_normalized_normalized.xlsx")]
    
    print(f"=== å³å¯†ãªåˆ—ã‚ºãƒ¬æ¤œè¨¼ ===")
    print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(files)}å€‹")
    
    # å„ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’åˆ†æ
    source_analyses = {}
    for file in sorted(files):
        file_path = os.path.join(base_dir, file)
        analysis = analyze_source_file_headers(file_path)
        if analysis:
            source_analyses[file] = analysis
            print(f"âœ… {file}: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ{analysis['header_row_index'] + 1}, æœ€å¤§åˆ—{analysis['max_col']}")
    
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ—ã‚ºãƒ¬ã‚’æ¤œå‡º
    print(f"\n=== ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ—ã‚ºãƒ¬æ¤œå‡º ===")
    misalignments = detect_semantic_misalignment(source_analyses, integrated_result)
    
    if misalignments:
        print(f"âš ï¸ æ¤œå‡ºã•ã‚ŒãŸåˆ—ã‚ºãƒ¬: {len(misalignments)}ä»¶")
        for mis in misalignments:
            print(f"  åˆ—{mis['column']} ({mis['header']}): {mis['mismatch_rate']:.1f}%ã®ãƒŸã‚¹ãƒãƒƒãƒ")
            print(f"    æœŸå¾…ãƒ‡ãƒ¼ã‚¿å‹: {mis['expected_type']}")
            print(f"    ã‚µãƒ³ãƒ—ãƒ«ãƒŸã‚¹ãƒãƒƒãƒ: {mis['sample_mismatches'][:3]}")
    else:
        print("âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ—ã‚ºãƒ¬ãªã— (0%)")
    
    # äººåã®ä½ç½®ç¢ºèªï¼ˆæ²³ç€¨é€å•é¡Œã®è©³ç´°åˆ†æï¼‰
    print(f"\n=== äººåãƒ‡ãƒ¼ã‚¿ã®ä½ç½®ç¢ºèª ===")
    wb = openpyxl.load_workbook(integrated_result, data_only=True)
    ws = wb.active
    
    person_name_columns = []
    product_name_columns = []
    
    # äººåã¨å•†å“åã®åˆ—ã‚’ç‰¹å®š
    for col in range(1, ws.max_column + 1):
        header = ws.cell(row=1, column=col).value
        if header:
            if 'ã”æ‹…å½“è€…æ§˜' in str(header) or 'æ‹…å½“è€…' in str(header):
                person_name_columns.append(col)
            elif 'å•†å“å' in str(header):
                product_name_columns.append(col)
    
    print(f"äººååˆ—: {[f'{openpyxl.utils.get_column_letter(c)}åˆ—' for c in person_name_columns]}")
    print(f"å•†å“ååˆ—: {[f'{openpyxl.utils.get_column_letter(c)}åˆ—' for c in product_name_columns]}")
    
    # æ²³ç€¨é€ã®å‡ºç¾ä½ç½®ã‚’è©³ç´°åˆ†æ
    kasegawa_positions = []
    for row in range(2, min(100, ws.max_row + 1)):
        for col in range(1, ws.max_column + 1):
            value = ws.cell(row=row, column=col).value
            if value and 'æ²³ç€¨' in str(value):
                header = ws.cell(row=1, column=col).value
                file_name = ws.cell(row=row, column=1).value
                kasegawa_positions.append({
                    'row': row, 'col': col, 'header': header,
                    'value': value, 'file': file_name,
                    'is_person_column': col in person_name_columns,
                    'is_product_column': col in product_name_columns
                })
    
    # åˆ—ã‚ºãƒ¬ç‡ã‚’è¨ˆç®—
    total_kasegawa = len(kasegawa_positions)
    misplaced_kasegawa = len([k for k in kasegawa_positions if k['is_product_column']])
    
    if total_kasegawa > 0:
        misplacement_rate = (misplaced_kasegawa / total_kasegawa) * 100
        print(f"\næ²³ç€¨é€ãƒ‡ãƒ¼ã‚¿åˆ†æ:")
        print(f"  ç·å‡ºç¾å›æ•°: {total_kasegawa}")
        print(f"  æ­£ã—ã„ä½ç½®(äººååˆ—): {total_kasegawa - misplaced_kasegawa}å›")
        print(f"  é–“é•ã£ãŸä½ç½®(å•†å“ååˆ—): {misplaced_kasegawa}å›")
        print(f"  åˆ—ã‚ºãƒ¬ç‡: {misplacement_rate:.2f}%")
        
        if misplaced_kasegawa > 0:
            print(f"\n  é–“é•ã£ãŸä½ç½®ã®è©³ç´°:")
            for k in kasegawa_positions:
                if k['is_product_column']:
                    col_letter = openpyxl.utils.get_column_letter(k['col'])
                    print(f"    è¡Œ{k['row']}, {col_letter}åˆ—({k['header']}): {k['value']} [ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(k['file'])}]")
    
    return {
        'total_files': len(files),
        'semantic_misalignments': misalignments,
        'kasegawa_analysis': {
            'total': total_kasegawa,
            'misplaced': misplaced_kasegawa,
            'misplacement_rate': misplacement_rate if total_kasegawa > 0 else 0
        }
    }

def strict_alignment_verification(municipality_name="ä¸æ•´åˆãƒ†ã‚¹ãƒˆè‡ªæ²»ä½“v3"):
    """
    åˆ—ã‚ºãƒ¬0%é”æˆã®å³å¯†ãªæ¤œè¨¼
    """
    base_dir = os.path.join(
        r'DATA\Phase3\HARV',
        municipality_name
    )
    
    if not os.path.exists(base_dir):
        print(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")
        return None
    
    integrated_result = os.path.join(base_dir, "dynamic_mapping_integration.xlsx")
    
    if not os.path.exists(integrated_result):
        print(f"çµ±åˆçµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {integrated_result}")
        return None
    
    # äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œ
    result = cross_validate_with_source_files(base_dir, integrated_result)
    
    # æœ€çµ‚åˆ¤å®š
    print(f"\n=== æœ€çµ‚åˆ—ã‚ºãƒ¬åˆ¤å®š ===")
    
    semantic_errors = len(result['semantic_misalignments'])
    kasegawa_misplacement_rate = result['kasegawa_analysis']['misplacement_rate']
    
    total_error_rate = max(kasegawa_misplacement_rate, 
                          (semantic_errors / result['total_files']) * 100 if result['total_files'] > 0 else 0)
    
    if total_error_rate == 0:
        print("ğŸ‰ åˆ—ã‚ºãƒ¬ 0.00% - å®Œç’§ãªæ•´åˆ—é”æˆï¼")
        verdict = "PERFECT"
    elif total_error_rate < 1:
        print(f"âš ï¸ åˆ—ã‚ºãƒ¬ {total_error_rate:.2f}% - è»½å¾®ãªå•é¡Œã‚ã‚Š")
        verdict = "MINOR_ISSUES"
    else:
        print(f"âŒ åˆ—ã‚ºãƒ¬ {total_error_rate:.2f}% - è¦ä¿®æ­£")
        verdict = "NEEDS_FIX"
    
    return {
        'verdict': verdict,
        'total_error_rate': total_error_rate,
        'details': result
    }

if __name__ == "__main__":
    result = strict_alignment_verification()
