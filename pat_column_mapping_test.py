import os
import json
from openpyxl import load_workbook, Workbook
from collections import defaultdict
import re

def create_column_mapping_config():
    """
    PATåˆ¥ã®åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’ä½œæˆ
    æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’åŸºã«ã€å„PATã§ã®å®Ÿéš›ã®ãƒ˜ãƒƒãƒ€ãƒ¼ä½ç½®ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
    """
    mapping_config = {
        "PAT0001_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "ã”è¨˜å…¥æ—¥": 4,  # ç©ºã®å ´åˆã‚ã‚Š
            "äº‹æ¥­è€…æ§˜å": 5,  # å®Ÿéš›ã¯ã€Œã”è¨˜å…¥æ—¥ã€ã ãŒäº‹æ¥­è€…æ§˜åã¨ã—ã¦æ‰±ã†
            "äº‹æ¥­è€…æ§˜TEL": 6,  # å®Ÿéš›ã¯ã€Œäº‹æ¥­è€…æ§˜åã€
            "ç™ºé€å…ƒåç§°": 7,  # å®Ÿéš›ã¯ã€Œäº‹æ¥­è€…æ§˜TELã€
            "ç™ºé€å…ƒä½æ‰€": 8,  # ã€Œè¿”ç¤¼å“ç™ºé€å…ƒæƒ…å ±ã€
            "ç™ºé€å…ƒTEL": 9,  # ã€Œè¿”ç¤¼å“ç™ºé€å…ƒæƒ…å ±ã€
            "ã”æ‹…å½“è€…æ§˜": 10, # ã€Œè¿”ç¤¼å“ç™ºé€å…ƒæƒ…å ±ã€
            "å•†å“å": 11,     # å®Ÿéš›ã¯ã€Œã”æ‹…å½“è€…æ§˜ã€ã ãŒå•†å“åã¨ã—ã¦æ‰±ã†
            "ç”£åœ°": 12,       # å®Ÿéš›ã®ã€Œç”£åœ°ã€
            "å†…å®¹é‡": 14,     # å®Ÿéš›ã¯ã€Œç”Ÿç”£è€…ãƒ»è£½é€ è€…ãƒ»åŠ å·¥å…ƒã€ã ãŒå†…å®¹é‡ã¨ã—ã¦æ‰±ã†
            "ç™ºé€æ¸©åº¦å¸¯": 20,
            "ä¿å­˜æ–¹æ³•": 21,   # å®Ÿéš›ã¯ã€Œç™ºé€æ¸©åº¦å¸¯ã€ã ãŒä¿å­˜æ–¹æ³•ã¨ã—ã¦æ‰±ã†
            "å—ä»˜æœŸé–“": 22,   # å®Ÿéš›ã¯ã€Œä¿å­˜æ–¹æ³•ã€ã ãŒå—ä»˜æœŸé–“ã¨ã—ã¦æ‰±ã†
            "ç™ºé€æœŸé–“": 24,   # å®Ÿéš›ã¯ã€Œå—ä»˜çµ‚äº†ã€ã ãŒç™ºé€æœŸé–“ã¨ã—ã¦æ‰±ã†
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 26, # å®Ÿéš›ã¯ã€Œç™ºé€çµ‚äº†ã€ã ãŒãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã¨ã—ã¦æ‰±ã†
        },
        "PAT0002_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "ã”è¨˜å…¥æ—¥": 4,
            "äº‹æ¥­è€…æ§˜å": 5,
            "äº‹æ¥­è€…æ§˜TEL": 6,
            "ç™ºé€å…ƒåç§°": 7,
            "ç™ºé€å…ƒä½æ‰€": 8,
            "ç™ºé€å…ƒTEL": 9,
            "ã”æ‹…å½“è€…æ§˜": 10,
            "å•†å“å": 11,
            "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)": 12,
            "å†…å®¹é‡": 24,
            "ç™ºé€æ¸©åº¦å¸¯": 31,
            "ä¿å­˜æ–¹æ³•": 32,
            "å—ä»˜æœŸé–“": 33,
            "ç™ºé€æœŸé–“": 35,
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 37,
        },
        "PAT0003_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰_2": 4,  # é‡è¤‡
            "ã”è¨˜å…¥æ—¥": 5,
            "äº‹æ¥­è€…æ§˜å": 6,
            "äº‹æ¥­è€…æ§˜TEL": 7,
            "ç™ºé€å…ƒåç§°": 8,
            "ç™ºé€å…ƒä½æ‰€": 9,
            "ç™ºé€å…ƒTEL": 10,
            "ã”æ‹…å½“è€…æ§˜": 11,
            "å•†å“å": 12,
            "å†…å®¹é‡": 15,
            "ç™ºé€æ¸©åº¦å¸¯": 21,
            "ä¿å­˜æ–¹æ³•": 22,
            "å—ä»˜æœŸé–“": 23,
            "ç™ºé€æœŸé–“": 25,
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 27,
        },
        "PAT0004_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "ã”è¨˜å…¥æ—¥": 4,
            "äº‹æ¥­è€…æ§˜å": 5,
            "äº‹æ¥­è€…æ§˜TEL": 6,
            "ç™ºé€å…ƒåç§°": 7,
            "ç™ºé€å…ƒä½æ‰€": 8,
            "ç™ºé€å…ƒTEL": 9,
            "ã”æ‹…å½“è€…æ§˜": 10,
            "å•†å“å": 11,
            "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)": 12,
            "å†…å®¹é‡": 24,
            "ç™ºé€æ¸©åº¦å¸¯": 31,
            "ä¿å­˜æ–¹æ³•": 32,
            "å—ä»˜æœŸé–“": 33,
            "ç™ºé€æœŸé–“": 35,
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 37,
        },
        "PAT0005_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "ã”è¨˜å…¥æ—¥": 4,
            "äº‹æ¥­è€…æ§˜å": 5,
            "äº‹æ¥­è€…æ§˜TEL": 6,
            "ç™ºé€å…ƒåç§°": 7,
            "ç™ºé€å…ƒä½æ‰€": 8,
            "ç™ºé€å…ƒTEL": 9,
            "ã”æ‹…å½“è€…æ§˜": 10,
            "å•†å“å": 11,
            "ç”£åœ°": 12,
            "å†…å®¹é‡": 14,
            "ç™ºé€æ¸©åº¦å¸¯": 20,
            "ä¿å­˜æ–¹æ³•": 21,
            "å—ä»˜æœŸé–“": 22,
            "ç™ºé€æœŸé–“": 24,
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 26,
        },
        "PAT0006_normalized.xlsx": {
            "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": 3,
            "ã”è¨˜å…¥æ—¥": 4,
            "äº‹æ¥­è€…æ§˜å": 5,
            "äº‹æ¥­è€…æ§˜TEL": 6,
            "ç™ºé€å…ƒåç§°": 7,
            "ç™ºé€å…ƒä½æ‰€": 8,
            "ç™ºé€å…ƒTEL": 9,
            "ã”æ‹…å½“è€…æ§˜": 10,
            "å•†å“å": 11,
            "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)": 12,
            "å†…å®¹é‡": 24,
            "ç™ºé€æ¸©åº¦å¸¯": 31,
            "ä¿å­˜æ–¹æ³•": 32,
            "å—ä»˜æœŸé–“": 33,
            "ç™ºé€æœŸé–“": 35,
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": 37,
        }
    }
    return mapping_config

def normalize_header_name(header):
    """
    ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’å®Œå…¨ä¸€æ„åŒ–ã™ã‚‹
    """
    if not header:
        return ""
    
    # åŸºæœ¬çš„ãªæ­£è¦åŒ–
    normalized = str(header).strip()
    
    # æ”¹è¡Œã€é€£ç¶šç©ºç™½ã‚’é™¤å»
    normalized = re.sub(r'\s+', ' ', normalized)
    
    # ä¸€æ„åŒ–ã®ãŸã‚ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«
    mapping_rules = {
        # äº‹æ¥­è€…é–¢é€£
        "äº‹æ¥­è€…æ§˜å": "äº‹æ¥­è€…æ§˜å",
        "äº‹æ¥­è€…å": "äº‹æ¥­è€…æ§˜å",
        "äº‹æ¥­è€…æ§˜TEL": "äº‹æ¥­è€…æ§˜TEL",
        "äº‹æ¥­è€…TEL": "äº‹æ¥­è€…æ§˜TEL",
        
        # ç™ºé€å…ƒé–¢é€£
        "ç™ºé€å…ƒåç§°": "ç™ºé€å…ƒåç§°",
        "ç™ºé€å…ƒ": "ç™ºé€å…ƒåç§°",
        "ç™ºé€å…ƒä½æ‰€": "ç™ºé€å…ƒä½æ‰€",
        "ä½æ‰€": "ç™ºé€å…ƒä½æ‰€",
        "ç™ºé€å…ƒTEL": "ç™ºé€å…ƒTEL",
        "TEL": "ç™ºé€å…ƒTEL",
        "ã”æ‹…å½“è€…æ§˜": "ã”æ‹…å½“è€…æ§˜",
        "æ‹…å½“è€…": "ã”æ‹…å½“è€…æ§˜",
        
        # å•†å“é–¢é€£
        "å•†å“å": "å•†å“å",
        "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)": "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)",
        "å•†å“åï¼ˆä¼ç¥¨è¨˜è¼‰ç”¨ï¼‰": "å•†å“å(ä¼ç¥¨è¨˜è¼‰ç”¨)",
        "ç”£åœ°": "ç”£åœ°",
        "å†…å®¹é‡": "å†…å®¹é‡",
        
        # æ—¥ä»˜ãƒ»æœŸé–“é–¢é€£
        "ã”è¨˜å…¥æ—¥": "ã”è¨˜å…¥æ—¥",
        "è¨˜å…¥æ—¥": "ã”è¨˜å…¥æ—¥",
        "å—ä»˜æœŸé–“": "å—ä»˜æœŸé–“",
        "å—ä»˜é–‹å§‹": "å—ä»˜æœŸé–“",
        "ç™ºé€æœŸé–“": "ç™ºé€æœŸé–“",
        "ç™ºé€é–‹å§‹": "ç™ºé€æœŸé–“",
        "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ",
        
        # ä¿å­˜ãƒ»é…é€é–¢é€£
        "ç™ºé€æ¸©åº¦å¸¯": "ç™ºé€æ¸©åº¦å¸¯",
        "æ¸©åº¦å¸¯": "ç™ºé€æ¸©åº¦å¸¯",
        "ä¿å­˜æ–¹æ³•": "ä¿å­˜æ–¹æ³•",
        
        # è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰
        "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰",
    }
    
    # å®Œå…¨ä¸€è‡´ã§ã®å¤‰æ›
    if normalized in mapping_rules:
        return mapping_rules[normalized]
    
    # éƒ¨åˆ†ä¸€è‡´ã§ã®å¤‰æ›
    for pattern, standard in mapping_rules.items():
        if pattern in normalized:
            return standard
    
    # å¤‰æ›ã•ã‚Œãªã‹ã£ãŸå ´åˆã¯ãã®ã¾ã¾è¿”ã™
    return normalized

def process_file_with_mapping(file_path, mapping_config, master_headers):
    """
    åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    """
    file_name = os.path.basename(file_path)
    
    if file_name not in mapping_config:
        print(f"  âš ï¸ ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šãªã—: {file_name}")
        return [], master_headers
    
    column_mapping = mapping_config[file_name]
    
    try:
        wb = load_workbook(file_path, data_only=True)
        ws = wb.active
        max_row = ws.max_row
        max_col = ws.max_column

        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã®å€¤ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼
        data = []
        for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
            data.append([cell.value for cell in row])

        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆBåˆ—ãŒã€Œé …ç›®ã€ï¼‰ã‚’æ¤œç´¢
        header_row_index = None
        for i, row in enumerate(data):
            if len(row) >= 2 and row[1] == "é …ç›®":
                header_row_index = i
                break

        if header_row_index is None:
            print(f"  âš ï¸ ã€Œé …ç›®ã€è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
            return [], master_headers

        # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã«åŸºã¥ã„ã¦æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç”Ÿæˆ
        standardized_headers = []
        for standard_name, column_index in column_mapping.items():
            normalized_name = normalize_header_name(standard_name)
            if normalized_name not in master_headers:
                master_headers.append(normalized_name)
            standardized_headers.append(normalized_name)

        # ãƒ‡ãƒ¼ã‚¿è¡Œå‡¦ç†
        output_rows = []
        for row in data[header_row_index+1:]:
            new_row = []
            
            # Aåˆ—: ãƒ•ã‚¡ã‚¤ãƒ«å
            existing_file_name = row[0] if len(row) > 0 and row[0] is not None else file_name
            new_row.append(existing_file_name)
            
            # Båˆ—: é …ç›®å€¤
            value_B = row[1] if len(row) > 1 else None
            new_row.append(value_B)
            
            # Cåˆ—ä»¥é™: ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®
            for header in master_headers:
                value = None
                # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã“ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«å¯¾å¿œã™ã‚‹ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ¢ã™
                for standard_name, column_index in column_mapping.items():
                    if normalize_header_name(standard_name) == header:
                        # 1-based ã‹ã‚‰ 0-based ã«å¤‰æ›
                        actual_index = column_index - 1
                        if actual_index < len(row):
                            value = row[actual_index]
                        break
                new_row.append(value)
            
            output_rows.append(new_row)

        print(f"  âœ… ãƒãƒƒãƒ”ãƒ³ã‚°å‡¦ç†å®Œäº†: {file_name} (è¡Œæ•°: {len(output_rows)}, æ¨™æº–ãƒ˜ãƒƒãƒ€ãƒ¼: {len(standardized_headers)})")
        return output_rows, master_headers
        
    except Exception as e:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {file_name} â†’ {e}")
        return [], master_headers

def validate_mapping_accuracy(base_dir, mapping_config):
    """
    ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã®ç²¾åº¦ã‚’æ¤œè¨¼
    """
    print("\n=== ãƒãƒƒãƒ”ãƒ³ã‚°ç²¾åº¦æ¤œè¨¼ ===")
    
    validation_results = {}
    
    for file_name, column_mapping in mapping_config.items():
        file_path = os.path.join(base_dir, file_name)
        if not os.path.exists(file_path):
            continue
            
        print(f"\n--- {file_name} ã®æ¤œè¨¼ ---")
        
        try:
            wb = load_workbook(file_path, data_only=True)
            ws = wb.active
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            data = []
            for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
                data.append([cell.value for cell in row])

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œç´¢
            header_row_index = None
            for i, row in enumerate(data):
                if len(row) >= 2 and row[1] == "é …ç›®":
                    header_row_index = i
                    break

            if header_row_index is None:
                continue

            # ãƒãƒƒãƒ”ãƒ³ã‚°ã®ç²¾åº¦ã‚’ãƒã‚§ãƒƒã‚¯
            accurate_mappings = 0
            total_mappings = 0
            
            for standard_name, column_index in column_mapping.items():
                total_mappings += 1
                actual_index = column_index - 1  # 1-based ã‹ã‚‰ 0-based
                
                if actual_index < len(data[header_row_index]):
                    actual_header = data[header_row_index][actual_index]
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    sample_data = []
                    for row_idx in range(header_row_index + 1, min(header_row_index + 4, len(data))):
                        if row_idx < len(data) and actual_index < len(data[row_idx]):
                            val = data[row_idx][actual_index]
                            if val is not None and str(val).strip():
                                sample_data.append(str(val).strip())
                    
                    print(f"  {standard_name} â†’ {column_index}åˆ—ç›®")
                    print(f"    å®Ÿéš›ã®ãƒ˜ãƒƒãƒ€ãƒ¼: {actual_header}")
                    print(f"    ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: {sample_data[:2]}")
                    
                    # ç²¾åº¦åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if is_mapping_accurate(standard_name, actual_header, sample_data):
                        accurate_mappings += 1
                        print(f"    âœ… é©åˆ‡")
                    else:
                        print(f"    âš ï¸ è¦ç¢ºèª")
            
            accuracy = (accurate_mappings / total_mappings) * 100 if total_mappings > 0 else 0
            validation_results[file_name] = {
                'accuracy': accuracy,
                'accurate': accurate_mappings,
                'total': total_mappings
            }
            print(f"  ğŸ“Š ç²¾åº¦: {accuracy:.1f}% ({accurate_mappings}/{total_mappings})")
            
        except Exception as e:
            print(f"  âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    return validation_results

def is_mapping_accurate(standard_name, actual_header, sample_data):
    """
    ãƒãƒƒãƒ”ãƒ³ã‚°ãŒé©åˆ‡ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    """
    # å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if actual_header == standard_name:
        return True
    
    # æ­£è¦åŒ–å¾Œã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if normalize_header_name(actual_header) == normalize_header_name(standard_name):
        return True
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å†…å®¹ä¸€è‡´ãƒã‚§ãƒƒã‚¯
    if standard_name in ["ã”è¨˜å…¥æ—¥"] and sample_data:
        # æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãƒã‚§ãƒƒã‚¯
        for sample in sample_data:
            if re.match(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}|^\d{5}$', sample):  # æ—¥ä»˜ã¾ãŸã¯Excelæ—¥ä»˜ã‚·ãƒªã‚¢ãƒ«
                return True
    
    if standard_name in ["äº‹æ¥­è€…æ§˜TEL", "ç™ºé€å…ƒTEL"] and sample_data:
        # é›»è©±ç•ªå·ã®å½¢å¼ãƒã‚§ãƒƒã‚¯
        for sample in sample_data:
            if re.match(r'[\d\-\(\)]+', sample):
                return True
    
    # ãã®ä»–ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ å¯èƒ½
    return False

def test_column_mapping_integration(municipality_name="ä¸æ•´åˆãƒ†ã‚¹ãƒˆè‡ªæ²»ä½“v3"):
    """
    åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã«ã‚ˆã‚‹çµ±åˆãƒ†ã‚¹ãƒˆ
    """
    base_dir = os.path.join(
        r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',
        municipality_name
    )
    
    if not os.path.exists(base_dir):
        print(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")
        return
    
    # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆé‡è¤‡æ­£è¦åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰
    files = [f for f in os.listdir(base_dir) 
             if f.startswith("PAT") and f.endswith("_normalized.xlsx") 
             and not f.endswith("_normalized_normalized.xlsx")]
    
    print(f"=== åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆ ===")
    print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(files)}å€‹")
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’ä½œæˆ
    mapping_config = create_column_mapping_config()
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’JSONã§ä¿å­˜
    mapping_path = os.path.join(base_dir, "column_mapping_config.json")
    with open(mapping_path, 'w', encoding='utf-8') as f:
        json.dump(mapping_config, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šä¿å­˜: {mapping_path}")
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ç²¾åº¦ã‚’æ¤œè¨¼
    validation_results = validate_mapping_accuracy(base_dir, mapping_config)
    
    print(f"\n=== ãƒãƒƒãƒ”ãƒ³ã‚°çµ±åˆå‡¦ç† ===")
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹çµ±åˆå‡¦ç†
    master_headers = []
    master_data_rows = []
    
    for file in sorted(files):
        file_path = os.path.join(base_dir, file)
        print(f"\n--- {file} ---")
        
        rows, master_headers = process_file_with_mapping(file_path, mapping_config, master_headers)
        master_data_rows.extend(rows)
    
    # çµ±åˆçµæœã‚’å‡ºåŠ›
    mapping_wb = Workbook()
    mapping_ws = mapping_wb.active
    mapping_ws.title = "mapping_based_integration"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    mapping_ws.cell(row=1, column=1, value="ãƒ•ã‚¡ã‚¤ãƒ«å")
    mapping_ws.cell(row=1, column=2, value="é …ç›®")
    for i, header in enumerate(master_headers, start=3):
        mapping_ws.cell(row=1, column=i, value=header)
    
    # ãƒ‡ãƒ¼ã‚¿è¨­å®š
    current_row = 2
    for row in master_data_rows:
        for j, value in enumerate(row, start=1):
            mapping_ws.cell(row=current_row, column=j, value=value)
        current_row += 1
    
    mapping_output_path = os.path.join(base_dir, "mapping_based_integration.xlsx")
    mapping_wb.save(mapping_output_path)
    
    print(f"\n=== çµ±åˆçµæœ ===")
    print(f"ğŸ“„ ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹çµ±åˆçµæœ: {mapping_output_path}")
    print(f"ğŸ“Š çµ±åˆãƒ˜ãƒƒãƒ€ãƒ¼æ•°: {len(master_headers)}")
    print(f"ğŸ“Š çµ±åˆãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(master_data_rows)}")
    
    # æ¤œè¨¼ã‚µãƒãƒªãƒ¼
    print(f"\n=== ãƒãƒƒãƒ”ãƒ³ã‚°ç²¾åº¦ã‚µãƒãƒªãƒ¼ ===")
    for file_name, result in validation_results.items():
        print(f"  {file_name}: {result['accuracy']:.1f}% ({result['accurate']}/{result['total']})")
    
    avg_accuracy = sum(r['accuracy'] for r in validation_results.values()) / len(validation_results) if validation_results else 0
    print(f"ğŸ“ˆ å¹³å‡ç²¾åº¦: {avg_accuracy:.1f}%")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ä¸€è¦§ã‚’è¡¨ç¤º
    print(f"\n=== çµ±åˆå¾Œã®æ¨™æº–ãƒ˜ãƒƒãƒ€ãƒ¼ä¸€è¦§ ===")
    for i, header in enumerate(master_headers, 1):
        print(f"  {i:2d}. {header}")
    
    print(f"\nâœ… åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
    
    return {
        'mapping_config': mapping_config,
        'validation_results': validation_results,
        'master_headers': master_headers,
        'total_rows': len(master_data_rows),
        'output_path': mapping_output_path
    }

if __name__ == "__main__":
    result = test_column_mapping_integration()
