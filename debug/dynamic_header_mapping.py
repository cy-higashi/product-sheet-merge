import os
import json
from openpyxl import load_workbook, Workbook
from collections import defaultdict
import re

def find_header_base_position(data):
    """
    å‹•çš„ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã®åŸºæº–ä½ç½®ã‚’æ¤œå‡º
    1. ã€Œé …ç›®ã€ã¨ã‚ã‚‹è¡Œã‚’æ¤œç´¢
    2. ã€Œè¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰ã€ãŒã‚ã‚‹åˆ—ã‚’æ¤œç´¢
    """
    header_row_index = None
    header_col_index = None
    
    # ã€Œé …ç›®ã€ã¨ã‚ã‚‹è¡Œã‚’æ¤œç´¢
    for i, row in enumerate(data):
        if len(row) >= 2 and row[1] == "é …ç›®":
            header_row_index = i
            break
    
    if header_row_index is None:
        return None, None
    
    # ã€Œè¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰ã€ãŒã‚ã‚‹åˆ—ã‚’æ¤œç´¢ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œå†…ã§ï¼‰
    for j, cell in enumerate(data[header_row_index]):
        if cell and "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰" in str(cell):
            header_col_index = j
            break
    
    return header_row_index, header_col_index

def extract_hierarchical_headers(data, header_row_index, header_col_start):
    """
    éšå±¤çš„ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‚’è§£æ
    ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã®é–¢ä¿‚ã‚’å‹•çš„ã«æŠ½å‡º
    """
    if header_row_index is None or header_col_start is None:
        return []
    
    main_row = data[header_row_index]
    sub_row = data[header_row_index + 1] if header_row_index + 1 < len(data) else []
    
    hierarchical_headers = []
    
    # header_col_start ã‹ã‚‰æœ€å¾Œã¾ã§è§£æ
    max_col = max(len(main_row), len(sub_row))
    
    for col_idx in range(header_col_start, max_col):
        main_header = main_row[col_idx] if col_idx < len(main_row) else None
        sub_header = sub_row[col_idx] if col_idx < len(sub_row) else None
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ç”Ÿæˆ
        header_info = create_unique_header_name(main_header, sub_header, col_idx, header_col_start)
        hierarchical_headers.append({
            'column_index': col_idx + 1,  # 1-based
            'main_header': main_header,
            'sub_header': sub_header,
            'unique_name': header_info['unique_name'],
            'standard_name': header_info['standard_name']
        })
    
    return hierarchical_headers

def create_unique_header_name(main_header, sub_header, col_idx, header_col_start):
    """
    ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ç”Ÿæˆ
    ç©ºã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‚ã€ŒPAT-ç©ºNã€å½¢å¼ã§ç®¡ç†
    """
    # åŸºæœ¬çš„ãªæ­£è¦åŒ–
    main_clean = normalize_text(main_header) if main_header else ""
    sub_clean = normalize_text(sub_header) if sub_header else ""
    
    # æ¨™æº–åã¸ã®å¤‰æ›ãƒ«ãƒ¼ãƒ«
    standard_mapping = {
        "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰": "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰",
        "ã”è¨˜å…¥æ—¥": "ã”è¨˜å…¥æ—¥",
        "äº‹æ¥­è€…æ§˜å": "äº‹æ¥­è€…æ§˜å",
        "äº‹æ¥­è€…æ§˜TEL": "äº‹æ¥­è€…æ§˜TEL",
        "å•†å“å": "å•†å“å",
        "ç”£åœ°": "ç”£åœ°",
        "å†…å®¹é‡": "å†…å®¹é‡",
        "ç™ºé€æ¸©åº¦å¸¯": "ç™ºé€æ¸©åº¦å¸¯",
        "ä¿å­˜æ–¹æ³•": "ä¿å­˜æ–¹æ³•",
        "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ": "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ",
    }
    
    # ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã®é‡è¦é …ç›®
    sub_mapping = {
        "ç™ºé€å…ƒåç§°": "ç™ºé€å…ƒåç§°",
        "ä½æ‰€": "ç™ºé€å…ƒä½æ‰€", 
        "TEL": "ç™ºé€å…ƒTEL",
        "ã”æ‹…å½“è€…æ§˜": "ã”æ‹…å½“è€…æ§˜",
        "å¿…é ˆ": "",  # å¿…é ˆè¡¨ç¤ºã¯ç„¡è¦–
        "ä»»æ„": "",  # ä»»æ„è¡¨ç¤ºã¯ç„¡è¦–
    }
    
    # æ¨™æº–åã®æ±ºå®š
    standard_name = None
    
    # 1. ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã§ã®å®Œå…¨ä¸€è‡´
    if main_clean in standard_mapping:
        standard_name = standard_mapping[main_clean]
    
    # 2. ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã§ã®å®Œå…¨ä¸€è‡´
    elif sub_clean in sub_mapping and sub_mapping[sub_clean]:
        standard_name = sub_mapping[sub_clean]
    
    # 3. ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã§ã®éƒ¨åˆ†ä¸€è‡´
    elif main_clean:
        for key, value in standard_mapping.items():
            if key in main_clean or main_clean in key:
                standard_name = value
                break
    
    # 4. ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼ã§ã®éƒ¨åˆ†ä¸€è‡´
    elif sub_clean:
        for key, value in sub_mapping.items():
            if key in sub_clean or sub_clean in key:
                if value:  # ç©ºæ–‡å­—ã§ãªã„å ´åˆã®ã¿
                    standard_name = value
                break
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯åã®ç”Ÿæˆ
    if main_clean and sub_clean and sub_clean not in ["å¿…é ˆ", "ä»»æ„"]:
        unique_name = f"{main_clean}:{sub_clean}"
    elif main_clean:
        unique_name = main_clean
    elif sub_clean and sub_clean not in ["å¿…é ˆ", "ä»»æ„"]:
        unique_name = sub_clean
    else:
        # ç©ºã®å ´åˆã¯åˆ—ä½ç½®ã§è­˜åˆ¥
        col_relative = col_idx - header_col_start + 1
        unique_name = f"ç©ºåˆ—{col_relative}"
    
    return {
        'unique_name': unique_name,
        'standard_name': standard_name or unique_name
    }

def normalize_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–
    """
    if not text:
        return ""
    
    text = str(text).strip()
    # æ”¹è¡Œã€é€£ç¶šç©ºç™½ã‚’é™¤å»
    text = re.sub(r'\s+', '', text)
    # ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»
    text = re.sub(r'[^\w\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', '', text)
    
    return text

def analyze_file_structure(file_path):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’å‹•çš„ã«è§£æ
    """
    file_name = os.path.basename(file_path)
    
    try:
        wb = load_workbook(file_path, data_only=True)
        ws = wb.active
        max_row = ws.max_row
        max_col = ws.max_column

        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã®å€¤ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼
        data = []
        for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
            data.append([cell.value for cell in row])

        # å‹•çš„ã«ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½®ã‚’æ¤œå‡º
        header_row_index, header_col_start = find_header_base_position(data)
        
        if header_row_index is None or header_col_start is None:
            print(f"  âš ï¸ ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
            return None
        
        print(f"  ğŸ“ {file_name}: ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½® è¡Œ{header_row_index + 1}, åˆ—{header_col_start + 1}")
        
        # éšå±¤çš„ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æŠ½å‡º
        hierarchical_headers = extract_hierarchical_headers(data, header_row_index, header_col_start)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        sample_data = {}
        for header_info in hierarchical_headers:
            col_idx = header_info['column_index'] - 1  # 0-based
            samples = []
            for row_idx in range(header_row_index + 2, min(header_row_index + 6, len(data))):
                if row_idx < len(data) and col_idx < len(data[row_idx]):
                    val = data[row_idx][col_idx]
                    if val is not None and str(val).strip():
                        samples.append(str(val).strip())
            sample_data[header_info['unique_name']] = samples[:3]
        
        return {
            'file_name': file_name,
            'header_row_index': header_row_index,
            'header_col_start': header_col_start,
            'hierarchical_headers': hierarchical_headers,
            'sample_data': sample_data
        }
        
    except Exception as e:
        print(f"  âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {file_name} â†’ {e}")
        return None

def create_dynamic_mapping_config(file_structures):
    """
    å‹•çš„è§£æçµæœã‹ã‚‰çµ±åˆãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’ä½œæˆ
    """
    mapping_config = {}
    all_standard_names = set()
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨™æº–åã‚’åé›†
    for structure in file_structures:
        for header_info in structure['hierarchical_headers']:
            all_standard_names.add(header_info['standard_name'])
    
    all_standard_names = sorted(list(all_standard_names))
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    for structure in file_structures:
        file_mapping = {}
        
        for header_info in structure['hierarchical_headers']:
            standard_name = header_info['standard_name']
            column_index = header_info['column_index']
            
            # åŒã˜æ¨™æº–åãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯åã§åŒºåˆ¥
            if standard_name in file_mapping:
                # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯åã‚’ä½¿ç”¨
                unique_key = f"{standard_name}_{header_info['unique_name']}"
                file_mapping[unique_key] = column_index
            else:
                file_mapping[standard_name] = column_index
        
        mapping_config[structure['file_name']] = file_mapping
    
    return mapping_config, all_standard_names

def process_file_with_dynamic_mapping(file_path, file_mapping, all_standard_names, master_headers):
    """
    å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    """
    file_name = os.path.basename(file_path)
    
    try:
        wb = load_workbook(file_path, data_only=True)
        ws = wb.active
        max_row = ws.max_row
        max_col = ws.max_column

        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã®å€¤ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼
        data = []
        for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
            data.append([cell.value for cell in row])

        # ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½®ã‚’å†æ¤œå‡º
        header_row_index, header_col_start = find_header_base_position(data)
        
        if header_row_index is None:
            print(f"  âš ï¸ ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_name}")
            return [], master_headers

        # ãƒã‚¹ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°
        for standard_name in all_standard_names:
            if standard_name not in master_headers:
                master_headers.append(standard_name)

        # ãƒ‡ãƒ¼ã‚¿è¡Œå‡¦ç†
        output_rows = []
        for row in data[header_row_index + 2:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ+ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®æ¬¡ã‹ã‚‰
            new_row = []
            
            # Aåˆ—: ãƒ•ã‚¡ã‚¤ãƒ«å
            existing_file_name = row[0] if len(row) > 0 and row[0] is not None else file_name
            new_row.append(existing_file_name)
            
            # Båˆ—: é …ç›®å€¤
            value_B = row[1] if len(row) > 1 else None
            new_row.append(value_B)
            
            # Cåˆ—ä»¥é™: å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®
            for standard_name in master_headers:
                value = None
                
                # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã“ã®æ¨™æº–åã«å¯¾å¿œã™ã‚‹åˆ—ã‚’æ¢ã™
                if standard_name in file_mapping:
                    column_index = file_mapping[standard_name]
                    actual_index = column_index - 1  # 1-based ã‹ã‚‰ 0-based
                    if actual_index < len(row):
                        value = row[actual_index]
                
                new_row.append(value)
            
            output_rows.append(new_row)

        print(f"  âœ… å‹•çš„å‡¦ç†å®Œäº†: {file_name} (è¡Œæ•°: {len(output_rows)})")
        return output_rows, master_headers
        
    except Exception as e:
        print(f"  âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_name} â†’ {e}")
        return [], master_headers

def test_dynamic_header_mapping(municipality_name="ä¸æ•´åˆãƒ†ã‚¹ãƒˆè‡ªæ²»ä½“v3"):
    """
    å‹•çš„ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ
    """
    base_dir = os.path.join(
        r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',
        municipality_name
    )
    
    if not os.path.exists(base_dir):
        print(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")
        return
    
    # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆé‡è¤‡æ­£è¦åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰
    files = [f for f in os.listdir(base_dir) 
             if f.startswith("PAT") and f.endswith("_normalized.xlsx") 
             and not f.endswith("_normalized_normalized.xlsx")]
    
    print(f"=== å‹•çš„ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ===")
    print(f"å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(files)}å€‹")
    
    # STEP 1: å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’å‹•çš„è§£æ
    print(f"\n=== STEP 1: ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ è§£æ ===")
    file_structures = []
    
    for file in sorted(files):
        file_path = os.path.join(base_dir, file)
        print(f"\n--- {file} ---")
        
        structure = analyze_file_structure(file_path)
        if structure:
            file_structures.append(structure)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‚’è¡¨ç¤º
            print(f"  ğŸ“‹ æ¤œå‡ºãƒ˜ãƒƒãƒ€ãƒ¼æ•°: {len(structure['hierarchical_headers'])}")
            for i, header_info in enumerate(structure['hierarchical_headers'][:10]):  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
                print(f"    {header_info['column_index']:2d}åˆ—ç›®: {header_info['unique_name']} â†’ {header_info['standard_name']}")
            
            if len(structure['hierarchical_headers']) > 10:
                print(f"    ... ä»– {len(structure['hierarchical_headers']) - 10} å€‹")
    
    # STEP 2: å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’ä½œæˆ
    print(f"\n=== STEP 2: å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šä½œæˆ ===")
    mapping_config, all_standard_names = create_dynamic_mapping_config(file_structures)
    
    # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šã‚’JSONã§ä¿å­˜
    dynamic_mapping_path = os.path.join(base_dir, "dynamic_mapping_config.json")
    with open(dynamic_mapping_path, 'w', encoding='utf-8') as f:
        json.dump(mapping_config, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šä¿å­˜: {dynamic_mapping_path}")
    
    print(f"ğŸ“Š çµ±åˆæ¨™æº–åæ•°: {len(all_standard_names)}")
    
    # STEP 3: å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°ã§çµ±åˆå‡¦ç†
    print(f"\n=== STEP 3: å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°çµ±åˆå‡¦ç† ===")
    
    master_headers = []
    master_data_rows = []
    
    for file in sorted(files):
        file_path = os.path.join(base_dir, file)
        file_mapping = mapping_config.get(file, {})
        
        print(f"\n--- {file} ---")
        rows, master_headers = process_file_with_dynamic_mapping(
            file_path, file_mapping, all_standard_names, master_headers
        )
        master_data_rows.extend(rows)
    
    # STEP 4: çµ±åˆçµæœã‚’å‡ºåŠ›
    print(f"\n=== STEP 4: çµæœå‡ºåŠ› ===")
    
    dynamic_wb = Workbook()
    dynamic_ws = dynamic_wb.active
    dynamic_ws.title = "dynamic_mapping_integration"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    dynamic_ws.cell(row=1, column=1, value="ãƒ•ã‚¡ã‚¤ãƒ«å")
    dynamic_ws.cell(row=1, column=2, value="é …ç›®")
    for i, header in enumerate(master_headers, start=3):
        dynamic_ws.cell(row=1, column=i, value=header)
    
    # ãƒ‡ãƒ¼ã‚¿è¨­å®š
    current_row = 2
    for row in master_data_rows:
        for j, value in enumerate(row, start=1):
            dynamic_ws.cell(row=current_row, column=j, value=value)
        current_row += 1
    
    dynamic_output_path = os.path.join(base_dir, "dynamic_mapping_integration.xlsx")
    dynamic_wb.save(dynamic_output_path)
    
    print(f"ğŸ“„ å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°çµ±åˆçµæœ: {dynamic_output_path}")
    print(f"ğŸ“Š çµ±åˆãƒ˜ãƒƒãƒ€ãƒ¼æ•°: {len(master_headers)}")
    print(f"ğŸ“Š çµ±åˆãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(master_data_rows)}")
    
    # STEP 5: è©³ç´°åˆ†æçµæœã‚’å‡ºåŠ›
    print(f"\n=== STEP 5: è©³ç´°åˆ†æ ===")
    
    analysis_path = os.path.join(base_dir, "header_analysis_report.json")
    analysis_report = {
        'file_structures': file_structures,
        'mapping_config': mapping_config,
        'all_standard_names': all_standard_names,
        'total_files': len(files),
        'total_headers': len(master_headers),
        'total_rows': len(master_data_rows)
    }
    
    with open(analysis_path, 'w', encoding='utf-8') as f:
        json.dump(analysis_report, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {analysis_path}")
    
    # çµ±åˆå¾Œã®ãƒã‚¹ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼ä¸€è¦§
    print(f"\n=== çµ±åˆå¾Œã®ãƒã‚¹ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼ä¸€è¦§ ===")
    for i, header in enumerate(master_headers, 1):
        print(f"  {i:2d}. {header}")
    
    print(f"\nâœ… å‹•çš„ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    return {
        'file_structures': file_structures,
        'mapping_config': mapping_config,
        'master_headers': master_headers,
        'total_rows': len(master_data_rows),
        'output_path': dynamic_output_path
    }

if __name__ == "__main__":
    result = test_dynamic_header_mapping()
