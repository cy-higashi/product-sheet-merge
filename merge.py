import os
import re
from pathlib import Path
import time
from datetime import datetime
import pandas as pd
from openpyxl import load_workbook, Workbook
from copy import copy

# ===== å®šæ•°è¨­å®š =====
# ç’°å¢ƒå¤‰æ•°ãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’åˆ©ç”¨
MUNICIPALITY_NAME = os.getenv('MUNICIPALITY_NAME', 'ç†Šæœ¬å¸‚')
TARGET_PATH = os.getenv('TARGET_PATH', r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD_ç®¡ç†è€…\ãƒ‡ãƒ¼ã‚¿ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆéƒ¨\DataOps\ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\å•†å“ç®¡ç†\test_data')

# å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
PHASE1_OUTPUT_DIR = os.path.join(
    r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase1\HARV',
    MUNICIPALITY_NAME
)
PHASE2_OUTPUT_DIR = os.path.join(
    r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase2\HARV',
    MUNICIPALITY_NAME
)
PHASE3_OUTPUT_DIR = os.path.join(
    r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',
    MUNICIPALITY_NAME
)
LOG_FILE_PATH = os.path.join(PHASE1_OUTPUT_DIR, "execution_log.txt")

# å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆ
for d in [PHASE1_OUTPUT_DIR, PHASE2_OUTPUT_DIR, PHASE3_OUTPUT_DIR]:
    if not os.path.exists(d):
        os.makedirs(d, exist_ok=True)

# ===== Phase1: ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ã¨ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ä½œæˆ =====
def process_phase1(target_path, municipality_name, phase1_output_dir, log_file_path):
    with open(log_file_path, 'a', encoding='utf-8') as log_file:
        log_file.write(f"\n\n==== Phase1 å®Ÿè¡Œé–‹å§‹: {datetime.now()} ====\nã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: {target_path}\n")
    
    target_path = Path(target_path)
    xlsx_files = []
    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®.xlsxãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    for folder in target_path.iterdir():
        if folder.is_dir() and re.match(r'^[a-zA-Z0-9]', folder.name):
            for xlsx_file in folder.glob('*.xlsx'):
                xlsx_files.append((folder.name, xlsx_file))
    
    with open(log_file_path, 'a', encoding='utf-8') as log_file:
        log_file.write(f"Found {len(xlsx_files)} xlsx files in target path\n")
    
    output_data = []       # ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ç”¨ãƒ‡ãƒ¼ã‚¿
    file_pattern_data = [] # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±
    pattern_counter = 0
    existing_patterns = {}

    def cache_merged_cells(sheet):
        merged_cells_cache = {}
        for merged_range in sheet.merged_cells.ranges:
            for row in range(merged_range.min_row, merged_range.max_row + 1):
                for col in range(merged_range.min_col, merged_range.max_col + 1):
                    merged_cells_cache[(row, col)] = (merged_range.min_row, merged_range.min_col)
        return merged_cells_cache

    def get_merged_cell_value(sheet, cell, merged_cells_cache):
        if (cell.row, cell.column) in merged_cells_cache:
            min_row, min_col = merged_cells_cache[(cell.row, cell.column)]
            return sheet.cell(min_row, min_col).value
        return cell.value

    def get_right_column_value(sheet, row, column, merged_cells_cache):
        if column + 1 <= sheet.max_column:
            right_col_cell = sheet.cell(row, column + 1)
            right_value = get_merged_cell_value(sheet, right_col_cell, merged_cells_cache)
            if right_value:
                return f"+++{right_value}"
        return ""

    def get_values_until_last_data(sheet, start_cell, merged_cells_cache):
        values = []
        empty_count = 0
        max_empty_cells = 10
        for r in range(start_cell.row + 1, sheet.max_row + 1):
            cell = sheet.cell(r, start_cell.column)
            value = get_merged_cell_value(sheet, cell, merged_cells_cache)
            if value is None or value == "":
                empty_count += 1
            else:
                empty_count = 0
                if r > start_cell.row + 1 and value == get_merged_cell_value(sheet, sheet.cell(r - 1, start_cell.column), merged_cells_cache):
                    right_value = get_right_column_value(sheet, r, start_cell.column, merged_cells_cache)
                    value = f"{value}{right_value}"
            values.append(value)
            if empty_count >= max_empty_cells:
                break
        return [v for v in values if v is not None and v != ""]

    def find_existing_pattern(pattern_data):
        for pattern_name, existing_pattern in existing_patterns.items():
            if pattern_data == existing_pattern:
                return pattern_name
        return None

    for i, (folder_name, xlsx_file) in enumerate(xlsx_files):
        file_path = str(xlsx_file)
        file_name = xlsx_file.name
        try:
            print(f"Processing file: {file_name}")
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"\nProcessing file: {file_name}\n")
            try:
                workbook = load_workbook(file_path, data_only=True)
            except Exception as e:
                with open(log_file_path, 'a', encoding='utf-8') as log_file:
                    log_file.write(f"Failed to load workbook {file_name}: {e}\n")
                continue
            sheet = workbook.active
            merged_cells_cache = cache_merged_cells(sheet)
            pattern_found = False
            file_id = None  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯IDã¯ä¸è¦
            for row in sheet.iter_rows():
                for cell in row:
                    cell_value = get_merged_cell_value(sheet, cell, merged_cells_cache)
                    if cell_value == 'è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰':
                        all_values = get_values_until_last_data(sheet, cell, merged_cells_cache)
                        existing_pattern_name = find_existing_pattern(all_values)
                        if existing_pattern_name:
                            file_pattern_data.append([municipality_name, folder_name, file_name, existing_pattern_name, file_id])
                        else:
                            pattern_counter += 1
                            pattern_name = f"PAT{str(pattern_counter).zfill(4)}"
                            output_data.append([pattern_name, f"{cell.column_letter}{cell.row}"] + all_values)
                            file_pattern_data.append([municipality_name, folder_name, file_name, pattern_name, file_id])
                            existing_patterns[pattern_name] = all_values
                        pattern_found = True
                        break
                if pattern_found:
                    break
            if not pattern_found:
                file_pattern_data.append([municipality_name, folder_name, file_name, 'ãªã—', file_id])
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"File {i+1}/{len(xlsx_files)} processed: {file_name}\n")
        except Exception as e:
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"Error processing {file_name}: {e}\n")
    
    if output_data:
        max_columns = max([len(row) for row in output_data])
        column_names = ['ãƒ‘ã‚¿ãƒ¼ãƒ³å', 'A1å½¢å¼'] + [f'åˆ—ã®å€¤_{i}' for i in range(1, max_columns - 1)]
        output_df = pd.DataFrame(output_data, columns=column_names)
        file_pattern_df = pd.DataFrame(file_pattern_data, columns=['è‡ªæ²»ä½“', 'ãƒ•ã‚©ãƒ«ãƒ€å', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'ãƒ‘ã‚¿ãƒ¼ãƒ³å', 'ãƒ•ã‚¡ã‚¤ãƒ«ID'])
        output_path = os.path.join(phase1_output_dir, f"{municipality_name}_ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§.xlsx")
        try:
            output_df.to_excel(output_path, index=False)
        except Exception as e:
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"Failed to save output Excel file: {e}\n")
        file_pattern_output_path = os.path.join(phase1_output_dir, f"{municipality_name}_ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³.xlsx")
        try:
            file_pattern_df.to_excel(file_pattern_output_path, index=False)
        except Exception as e:
            with open(log_file_path, 'a', encoding='utf-8') as log_file:
                log_file.write(f"Failed to save file pattern Excel file: {e}\n")
        with open(log_file_path, 'a', encoding='utf-8') as log_file:
            log_file.write(f"\nResults saved to: {output_path}\nFile patterns saved to: {file_pattern_output_path}\n")
            log_file.write(f"==== Phase1 å®Ÿè¡Œçµ‚äº†: {datetime.now()} ====\n\n")

# ===== Phase2: ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§_Phase2.xlsx ä½œæˆ =====
def process_phase2(municipality_name, phase1_output_dir, phase2_output_dir):
    input_file = os.path.join(phase1_output_dir, f"{municipality_name}_ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§.xlsx")
    output_file = os.path.join(phase2_output_dir, f"{municipality_name}_ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§_Phase2.xlsx")
    df = pd.read_excel(input_file, sheet_name="Sheet1", header=None)
    df = df.fillna("")
    data = df.values.tolist()
    data = [row for row in data if str(row[0]).strip() != ""]
    last_row = len(data)
    if last_row == 0:
        raise ValueError("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    total_columns = len(data[0])
    unique_headers = {}
    header_order = []
    for col in range(total_columns - 1, 1, -1):
        for r in range(1, last_row):
            cell_value = str(data[r][col]).strip()
            if cell_value != "":
                if cell_value not in unique_headers:
                    unique_headers[cell_value] = True
                    header_order.append(cell_value)
    headers = header_order[::-1]
    new_data = []
    new_header_row = [data[0][0], data[0][1]] + headers
    new_data.append(new_header_row)
    for r in range(1, last_row):
        new_row = [data[r][0], data[r][1]]
        row_data = {}
        for cell in data[r]:
            cell_str = str(cell).strip()
            if cell_str != "":
                row_data[cell_str] = cell_str
        for h in headers:
            new_row.append(row_data.get(h, ""))
        new_data.append(new_row)
    for i, row in enumerate(new_data):
        if i == 0:
            row.insert(2, "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰")
        else:
            if isinstance(row[0], str) and row[0].startswith("PAT"):
                row.insert(2, "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰")
            else:
                row.insert(2, "")
    num_rows = len(new_data)
    num_cols = len(new_data[0])
    col_counts = []
    for col in range(num_cols):
        count = sum(1 for row in new_data[1:] if str(row[col]).strip() != "")
        col_counts.append((col, count))
    col_counts_sorted = sorted(col_counts, key=lambda x: x[1], reverse=True)
    reordered_data = []
    for row in new_data:
        new_row = [row[col_index] for col_index, _ in col_counts_sorted]
        reordered_data.append(new_row)
    output_df = pd.DataFrame(reordered_data)
    output_df.to_excel(output_file, index=False, header=False)
    print(f"Phase2 ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\nå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")

# ===== Phase3: å„ãƒ•ã‚¡ã‚¤ãƒ«ã®è»¢ç½®å‡¦ç† =====
def load_pattern_map(def_file, sheet_name="Sheet1"):
    try:
        df = pd.read_excel(def_file, sheet_name=sheet_name)
    except Exception as e:
        print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ã‚·ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return {}
    pattern_map = {}
    if df.empty:
        return pattern_map
    pattern_col = df.columns[0]
    output_cols = list(df.columns[1:])
    for idx, row in df.iterrows():
        pattern_name = str(row[pattern_col]).strip() if pd.notna(row[pattern_col]) else ""
        if not pattern_name:
            continue
        mapping = {}
        for col in output_cols:
            cell_val = row[col]
            if pd.notna(cell_val):
                keyword = str(cell_val).strip()
                if keyword.startswith("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰_"):
                    keyword = keyword.replace("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰_", "")
            else:
                keyword = ""
            mapping[col] = keyword
        pattern_map[pattern_name] = mapping
    return pattern_map

def load_file_list(list_file, sheet_name="Sheet1"):
    try:
        df = pd.read_excel(list_file, sheet_name=sheet_name)
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚·ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return None
    required_columns = ["è‡ªæ²»ä½“", "ãƒ•ã‚©ãƒ«ãƒ€å", "ãƒ•ã‚¡ã‚¤ãƒ«å", "ãƒ‘ã‚¿ãƒ¼ãƒ³å"]
    for col in required_columns:
        if col not in df.columns:
            print(f"å¿…è¦ãªåˆ— '{col}' ãŒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã«ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None
    return df

def process_file_phase3(file_path, combined_ws, start_output_row):
    wb = load_workbook(file_path)
    ws = wb.active
    start_cell = None
    for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
        for cell in row:
            if cell.value == "No.":
                start_cell = cell
                break
        if start_cell:
            break
    if not start_cell:
        for row in ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
            for cell in row:
                if cell.value == "é …ç›®":
                    start_cell = cell
                    break
            if start_cell:
                break
    if not start_cell:
        raise ValueError(f'"No." ã¾ãŸã¯ "é …ç›®" ãŒ {file_path} å†…ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚')
    start_row, start_col = start_cell.row, start_cell.column
    end_col_candidate = None
    if start_cell.value == "é …ç›®":
        for merged_range in ws.merged_cells.ranges:
            if start_cell.coordinate in merged_range:
                start_col = merged_range.min_col
                end_col_candidate = merged_range.max_col
                break
    end_row = start_row
    for r in range(start_row, ws.max_row + 1):
        if any(ws.cell(row=r, column=c).value is not None for c in range(start_col, ws.max_column + 1)):
            end_row = r
    end_col = start_col
    for c in range(start_col, ws.max_column + 1):
        if any(ws.cell(row=r, column=c).value is not None for r in range(start_row, end_row + 1)):
            end_col = c
    if end_col_candidate is not None and end_col_candidate > end_col:
        end_col = end_col_candidate
    orig_rows = end_row - start_row + 1
    orig_cols = end_col - start_col + 1
    for r_idx, r in enumerate(range(start_row, end_row + 1), start=1):
        for c_idx, c in enumerate(range(start_col, end_col + 1), start=1):
            orig_cell = ws.cell(row=r, column=c)
            final_row = start_output_row + (c_idx - 1)
            final_col = r_idx + 1
            new_cell = combined_ws.cell(row=final_row, column=final_col, value=orig_cell.value)
            if orig_cell.has_style:
                new_cell.font = copy(orig_cell.font)
                new_cell.border = copy(orig_cell.border)
                new_cell.fill = copy(orig_cell.fill)
                new_cell.number_format = copy(orig_cell.number_format)
                new_cell.protection = copy(orig_cell.protection)
                new_cell.alignment = copy(orig_cell.alignment)
    filename = file_path  # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    for offset in range(orig_cols):
        combined_ws.cell(row=start_output_row + offset, column=1, value=filename)
    for merged_range in ws.merged_cells.ranges:
        if (merged_range.min_row >= start_row and merged_range.max_row <= end_row and
            merged_range.min_col >= start_col and merged_range.max_col <= end_col):
            new_start_row = merged_range.min_col - start_col + 1
            new_start_col = merged_range.min_row - start_row + 1
            new_end_row = merged_range.max_col - start_col + 1
            new_end_col = merged_range.max_row - start_row + 1
            final_start_row = start_output_row + new_start_row - 1
            final_start_col = new_start_col + 1  # Aåˆ—ã¯ãƒ•ã‚¡ã‚¤ãƒ«åç”¨
            final_end_row = start_output_row + new_end_row - 1
            final_end_col = new_end_col + 1
            combined_ws.merge_cells(start_row=final_start_row, start_column=final_start_col,
                                      end_row=final_end_row, end_column=final_end_col)
    return orig_cols

def process_phase3():
    start_time = datetime.now()
    print(f"Phase3 å‡¦ç†é–‹å§‹: {start_time}")
    # Phase2ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ã¨ã—ã¦ã€Phase1ã®ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…ƒã«å‡¦ç†
    pattern_definitions_file = os.path.join(PHASE2_OUTPUT_DIR, f"{MUNICIPALITY_NAME}_ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸€è¦§_Phase2.xlsx")
    file_list_file = os.path.join(PHASE1_OUTPUT_DIR, f"{MUNICIPALITY_NAME}_ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³.xlsx")
    pattern_map = load_pattern_map(pattern_definitions_file, sheet_name="Sheet1")
    if not pattern_map:
        print("ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©ãŒç©ºã¾ãŸã¯èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚")
        return
    file_list_df = load_file_list(file_list_file, sheet_name="Sheet1")
    if file_list_df is None:
        print("ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ãŒç©ºã¾ãŸã¯èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚")
        return
    pattern_books = {}
    for idx, row in file_list_df.iterrows():
        municipality = str(row["è‡ªæ²»ä½“"]).strip()
        folder_name = str(row["ãƒ•ã‚©ãƒ«ãƒ€å"]).strip()
        file_name = str(row["ãƒ•ã‚¡ã‚¤ãƒ«å"]).strip()
        pattern_name = str(row["ãƒ‘ã‚¿ãƒ¼ãƒ³å"]).strip()
        print(f"å‡¦ç†ä¸­: {folder_name}\\{file_name}  ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern_name}")
        if pattern_name == "ãªã—":
            continue
        if pattern_name not in pattern_map:
            print(f"  â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³æœªå®šç¾©: {pattern_name}")
            continue
        file_path = os.path.join(TARGET_PATH, folder_name, file_name)
        if not os.path.exists(file_path):
            print(f"  â†’ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            continue
        if pattern_name not in pattern_books:
            new_wb = Workbook()
            new_ws = new_wb.active
            pattern_books[pattern_name] = {"wb": new_wb, "ws": new_ws, "current_row": 1}
        else:
            new_wb = pattern_books[pattern_name]["wb"]
            new_ws = pattern_books[pattern_name]["ws"]
        current_row = pattern_books[pattern_name]["current_row"]
        try:
            block_rows = process_file_phase3(file_path, new_ws, current_row)
            pattern_books[pattern_name]["current_row"] = current_row + block_rows
        except Exception as e:
            print(f"  â†’ {file_path} ã®å‡¦ç†ã«å¤±æ•—: {e}")
            continue
        time.sleep(1)
    for pattern_name, book_info in pattern_books.items():
        output_file = os.path.join(PHASE3_OUTPUT_DIR, f"{pattern_name}.xlsx")
        try:
            book_info["wb"].save(output_file)
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ã€{pattern_name}ã€‘ã®è»¢ç½®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
        except Exception as e:
            print(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ã€{pattern_name}ã€‘ã®ä¿å­˜ã«å¤±æ•—: {e}")
    end_time = datetime.now()
    print(f"Phase3 å‡¦ç†çµ‚äº†: {end_time}  çµŒéæ™‚é–“: {end_time - start_time}")

import os
from openpyxl import load_workbook, Workbook

def is_effectively_empty(cell_value, col_index=None):
    """
    ã‚»ãƒ«ã®å€¤ãŒNoneã¾ãŸã¯ç©ºæ–‡å­—ã®å ´åˆã¯Trueã‚’è¿”ã™ã€‚
    ã¾ãŸã€ç‰¹å®šã®åˆ—ã«ã¤ã„ã¦ã¯ã‚¨ãƒ©ãƒ¼ãƒ»ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å€¤ã‚‚ç©ºã¨è¦‹ãªã™ã€‚
    
    ä¾‹:
      - Yåˆ—ï¼ˆcol_index==25ï¼‰ï¼š"ç™ºé€æ¸©åº¦å¸¯ã‚’é¸æŠã—ã¦ãã ã•ã„"
      - ANåˆ—ï¼ˆcol_index==40ï¼‰ï¼š"é…é€æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„"
    """
    if cell_value is None or cell_value == '':
        return True
    if col_index == 25 and cell_value == "ç™ºé€æ¸©åº¦å¸¯ã‚’é¸æŠã—ã¦ãã ã•ã„":
        return True
    if col_index == 40 and cell_value == "é…é€æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„":
        return True
    return False

def combine_rows(row1, row2, col_count):
    """
    2è¡Œåˆ†ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆã—ã¾ã™ã€‚
    ã™ã¹ã¦ã®ã‚»ãƒ«ã«ã¤ã„ã¦ã€ä¸¡è¡Œã¨ã‚‚éç©ºã®å ´åˆã¯æ–‡å­—åˆ—ã¨ã—ã¦é€£çµã€
    ç‰‡æ–¹ã®ã¿éç©ºãªã‚‰ãã®å€¤ã‚’ã€ä¸¡æ–¹ç©ºãªã‚‰ç©ºæ–‡å­—ã¨ã—ã¾ã™ã€‚
    ãªãŠã€ä¸¡è€…ãŒå®Œå…¨ä¸€è‡´ã—ã¦ã„ã‚‹å ´åˆã¯ã€é‡è¤‡ã‚’é˜²ã„ã§1ã¤ã ã‘æ¡ç”¨ã—ã¾ã™ã€‚
    """
    combined = []
    for i in range(col_count):
        val1 = row1[i] if row1[i] is not None else ""
        val2 = row2[i] if row2[i] is not None else ""
        # ä¸¡æ–¹ç©ºãªã‚‰çµæœã‚‚ç©º
        if not val1 and not val2:
            combined.append("")
        # ä¸¡æ–¹éç©ºã®å ´åˆ
        elif val1 and val2:
            # å®Œå…¨ä¸€è‡´ãªã‚‰ä¸€æ–¹ã®ã¿
            if str(val1) == str(val2):
                combined.append(val1)
            else:
                # ä¸¡æ–¹ç•°ãªã‚‹å ´åˆã¯é€£çµï¼ˆãã®ã¾ã¾é€£çµï¼‰
                combined.append(str(val1) + str(val2))
        else:
            # ç‰‡æ–¹ã ã‘éç©ºãªã‚‰ãã®å€¤
            combined.append(val1 or val2)
    return combined

def process_file_phase4(file_path, output_path):
    # data_only=True ã§ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã¿ã€è¨ˆç®—çµæœï¼ˆå€¤ã®ã¿ï¼‰ã‚’å–å¾—
    wb = load_workbook(file_path, data_only=True)
    ws = wb.active

    max_row = ws.max_row
    max_col = ws.max_column

    print(f"ãƒ‡ãƒãƒƒã‚°: {os.path.basename(file_path)} - Max row: {max_row}, Max col: {max_col}")

    # â‘  ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚’å€¤ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã«ã‚³ãƒ”ãƒ¼ï¼ˆå€¤ã®ã¿è²¼ã‚Šä»˜ã‘ï¼‰
    data = []
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
        data.append([cell.value for cell in row])
    
    print(f"ãƒ‡ãƒãƒƒã‚°: ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(data)}")
    if data:
        print(f"ãƒ‡ãƒãƒƒã‚°: data[0] type: {type(data[0])}, length: {len(data[0]) if isinstance(data[0], list) else 'N/A'}")
        print(f"ãƒ‡ãƒãƒƒã‚°: data[0] content: {data[0][:5] if isinstance(data[0], list) else data[0]}")  # æœ€åˆã®5è¦ç´ ã®ã¿
        if len(data) > 1:
            print(f"ãƒ‡ãƒãƒƒã‚°: data[1] type: {type(data[1])}, length: {len(data[1]) if isinstance(data[1], list) else 'N/A'}")
            print(f"ãƒ‡ãƒãƒƒã‚°: data[1] content: {data[1][:5] if isinstance(data[1], list) else data[1]}")  # æœ€åˆã®5è¦ç´ ã®ã¿
    
    # â‘¡ çµåˆã‚»ãƒ«ã®è§£é™¤ï¼šå„çµåˆç¯„å›²ã«ã¤ã„ã¦ã€ä¸Šä½ã‚»ãƒ«ã®å€¤ã§å…¨ã‚»ãƒ«ã‚’åŸ‹ã‚ã‚‹
    for merged_range in ws.merged_cells.ranges:
        r1, r2 = merged_range.min_row, merged_range.max_row
        c1, c2 = merged_range.min_col, merged_range.max_col
        top_left_value = data[r1 - 1][c1 - 1]
        for r in range(r1, r2 + 1):
            for c in range(c1, c2 + 1):
                data[r - 1][c - 1] = top_left_value

    # â‘¢ ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¨ãƒ‡ãƒ¼ã‚¿è¡Œã«åˆ†å‰²
    # Phase3ã®å‡ºåŠ›æ§‹é€ : 1è¡Œç›®=ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€2è¡Œç›®=ãƒ˜ãƒƒãƒ€ãƒ¼ã€3è¡Œç›®ä»¥é™=ãƒ‡ãƒ¼ã‚¿
    if not data:
        print(f"è­¦å‘Š: {os.path.basename(file_path)} ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    if len(data) < 2:
        print(f"è­¦å‘Š: {os.path.basename(file_path)} ã«ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒã‚ã‚Šã¾ã›ã‚“")
        return
        
    # Phase3ã®æ§‹é€ ã«åˆã‚ã›ã¦ã€2è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ä½¿ç”¨
    header = data[1]  # 2è¡Œç›®ãŒãƒ˜ãƒƒãƒ€ãƒ¼
    # headerãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    if not isinstance(header, list):
        print(f"è­¦å‘Š: {os.path.basename(file_path)} ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(header)}")
        return
        
    col_count = len(header)
    data_rows = data[2:]  # 3è¡Œç›®ä»¥é™ãŒãƒ‡ãƒ¼ã‚¿è¡Œ

    # â‘£ Båˆ—ï¼ˆ2åˆ—ç›®ï¼‰ã®å€¤ã‚’ã‚­ãƒ¼ã¨ã—ã¦ã€é€£ç¶šã™ã‚‹è¡Œã§ã‚ã‚Œã°çµ±åˆã™ã‚‹
    merged_rows = []
    if data_rows:
        current_record = data_rows[0]
        # current_recordãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        if not isinstance(current_record, list):
            print(f"è­¦å‘Š: {os.path.basename(file_path)} ã®æœ€åˆã®ãƒ‡ãƒ¼ã‚¿è¡ŒãŒãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(current_record)}")
            return
            
        for next_row in data_rows[1:]:
            # next_rowãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if not isinstance(next_row, list):
                print(f"è­¦å‘Š: {os.path.basename(file_path)} ã®ãƒ‡ãƒ¼ã‚¿è¡ŒãŒãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(next_row)}")
                continue
                
            # é€£ç¶šã™ã‚‹è¡Œã‹ã©ã†ã‹ã¯Båˆ—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹1ï¼‰ã®å€¤ã§åˆ¤æ–­
            if len(next_row) > 1 and len(current_record) > 1 and next_row[1] == current_record[1]:
                # æ—¢ã«é€£çµã•ã‚Œã¦ã„ã‚‹è¡ŒåŒå£«ã¯ã€å„åˆ—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é€£çµã™ã‚‹
                current_record = combine_rows(current_record, next_row, col_count)
            else:
                merged_rows.append(current_record)
                current_record = next_row
        merged_rows.append(current_record)

    # â‘¤ æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã«å‡ºåŠ›
    new_wb = Workbook()
    new_ws = new_wb.active
    
    # headerãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰è¿½åŠ 
    if isinstance(header, list):
        new_ws.append(header)
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {os.path.basename(file_path)} ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
        
    for record in merged_rows:
        # recordãŒãƒªã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰è¿½åŠ 
        if isinstance(record, list):
            new_ws.append(record)
        else:
            print(f"è­¦å‘Š: {os.path.basename(file_path)} ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒãƒªã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“: {type(record)}")
            continue
    
    new_wb.save(output_path)
    print(f"æ­£å¸¸çµ‚äº†: {os.path.basename(output_path)} ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

def process_phase4():
    municipality = os.environ.get("MUNICIPALITY_NAME")
    if not municipality:
        print("MUNICIPALITY_NAME ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    base_dir = os.path.join(
        r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',
        municipality
    )

    if not os.path.exists(base_dir):
        print(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")
        return

    print(f"MUNICIPALITY_NAME = {municipality}")
    print(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€: {base_dir}")

    files = [f for f in os.listdir(base_dir) if f.startswith("PAT") and f.endswith(".xlsx")]
    if not files:
        print("PATã§å§‹ã¾ã‚‹xlsxãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    for file in files:
        input_path = os.path.join(base_dir, file)
        output_path = os.path.join(base_dir, file.replace(".xlsx", "_normalized.xlsx"))
        try:
            print(f"å‡¦ç†é–‹å§‹: {file}")
            process_file_phase4(input_path, output_path)
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: {file} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ â†’ {e}")
            import traceback
            traceback.print_exc()

import os

from openpyxl import load_workbook, Workbook



def normalize_header_text(text):
    """
    ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–ï¼ˆæ”¹è¡Œãƒ»ç©ºç™½ã®å‡¦ç†ï¼‰
    """
    if not text:
        return ""
    text = str(text).strip()
    # æ”¹è¡Œã€é€£ç¶šç©ºç™½ã‚’é™¤å»
    import re
    text = re.sub(r'\s+', '', text)
    return text

def create_hierarchical_header(main_header, sub_header, col_index, header_col_start):
    """
    éšå±¤çš„ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‹ã‚‰æ„å‘³çš„ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ç”Ÿæˆ
    """
    main_clean = normalize_header_text(main_header) if main_header else ""
    sub_clean = normalize_header_text(sub_header) if sub_header else ""
    
    # éšå±¤æ§‹é€ ã®å‡¦ç†
    if main_clean and sub_clean and sub_clean not in ["å¿…é ˆ", "ä»»æ„"]:
        return f"{main_clean}:{sub_clean}"
    elif main_clean:
        return main_clean
    elif sub_clean and sub_clean not in ["å¿…é ˆ", "ä»»æ„"]:
        return sub_clean
    else:
        # ç©ºã®å ´åˆã¯åˆ—ä½ç½®ã§è­˜åˆ¥
        col_relative = col_index - header_col_start + 1
        return f"ç©ºåˆ—{col_relative}"

def find_header_base_position(data):
    """
    å‹•çš„ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã®åŸºæº–ä½ç½®ã‚’æ¤œå‡º
    1. ã€Œé …ç›®ã€ã¨ã‚ã‚‹è¡Œã‚’æ¤œç´¢
    2. ã€Œè¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰ã€ãŒã‚ã‚‹åˆ—ã‚’æ¤œç´¢
    """
    header_row_index = None
    header_col_index = None
    
    # ã€Œé …ç›®ã€ã¨ã‚ã‚‹è¡Œã‚’æ¤œç´¢
    for i, row in enumerate(data):
        if len(row) >= 2 and row[1] == "é …ç›®":
            header_row_index = i
            break
    
    if header_row_index is None:
        return None, None
    
    # ã€Œè¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰ã€ãŒã‚ã‚‹åˆ—ã‚’æ¤œç´¢ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œå†…ã§ï¼‰
    for j, cell in enumerate(data[header_row_index]):
        if cell and "è¿”ç¤¼å“ã‚³ãƒ¼ãƒ‰" in str(cell):
            header_col_index = j
            break
    
    return header_row_index, header_col_index

def extract_dynamic_headers(data, header_row_index, header_col_start):
    """
    å‹•çš„ã«ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‚’è§£æã—ã€æ„å‘³çš„ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç”Ÿæˆ
    """
    if header_row_index is None or header_col_start is None:
        return []
    
    main_row = data[header_row_index]
    sub_row = data[header_row_index + 1] if header_row_index + 1 < len(data) else []
    
    dynamic_headers = []
    max_col = max(len(main_row), len(sub_row))
    
    for col_idx in range(header_col_start, max_col):
        main_header = main_row[col_idx] if col_idx < len(main_row) else None
        sub_header = sub_row[col_idx] if col_idx < len(sub_row) else None
        
        # éšå±¤çš„ãƒ˜ãƒƒãƒ€ãƒ¼åã‚’ç”Ÿæˆ
        header_name = create_hierarchical_header(main_header, sub_header, col_idx, header_col_start)
        dynamic_headers.append({
            'column_index': col_idx + 1,  # 1-based
            'header_name': header_name
        })
    
    return dynamic_headers

def update_master_headers(master_headers, source_headers):
    """
    source_headers å†…ã®å„é …ç›®ã«ã¤ã„ã¦ã€master_headers ã«
    å®Œå…¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒãªã‘ã‚Œã°è¿½åŠ ã™ã‚‹ã€‚
    ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚‚å«ã‚ãŸå®Œå…¨ä¸€è‡´åˆ¤å®šã‚’è¡Œã„ã¾ã™ï¼‰
    """
    for header in source_headers:
        if header not in master_headers:
            master_headers.append(header)
    return master_headers



def process_file(file_path, master_headers):
    """
    ï¼‘ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ï¼ˆåˆ—ã‚ºãƒ¬0%å¯¾å¿œç‰ˆï¼‰ã€‚
    
    ãƒ»å‹•çš„ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œå‡ºã«ã‚ˆã‚Šã€PATåˆ¥ã®æ§‹é€ å·®ç•°ã‚’å¸å
    ãƒ»éšå±¤çš„ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆãƒ¡ã‚¤ãƒ³+ã‚µãƒ–ï¼‰ã®æ„å‘³çš„çµ±åˆ
    ãƒ»ä½ç½®ã«ä¾å­˜ã—ãªã„å†…å®¹ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    """
    wb = load_workbook(file_path, data_only=True)
    ws = wb.active
    max_row = ws.max_row
    max_col = ws.max_column

    # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå…¨ä½“ã®å€¤ã‚’2æ¬¡å…ƒãƒªã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼
    data = []
    for row in ws.iter_rows(min_row=1, max_row=max_row, min_col=1, max_col=max_col):
        data.append([cell.value for cell in row])

    # å‹•çš„ã«ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½®ã‚’æ¤œå‡º
    header_row_index, header_col_start = find_header_base_position(data)
    
    if header_row_index is None or header_col_start is None:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«ãƒ˜ãƒƒãƒ€ãƒ¼åŸºæº–ä½ç½®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {os.path.basename(file_path)} â†’ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return [], master_headers

    # å‹•çš„ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ ã‚’è§£æ
    dynamic_headers = extract_dynamic_headers(data, header_row_index, header_col_start)
    
    # ã‚½ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æŠ½å‡ºï¼ˆæ„å‘³çš„ãƒ˜ãƒƒãƒ€ãƒ¼åï¼‰
    source_headers = [header_info['header_name'] for header_info in dynamic_headers]
    master_headers = update_master_headers(master_headers, source_headers)

    # ãƒ˜ãƒƒãƒ€ãƒ¼å â†’ åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    header_to_column = {header_info['header_name']: header_info['column_index'] 
                       for header_info in dynamic_headers}

    # ãƒ‡ãƒ¼ã‚¿è¡Œå‡¦ç†
    output_rows = []
    for row in data[header_row_index + 2:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ+ã‚µãƒ–ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®æ¬¡ã‹ã‚‰
        new_row = []
        
        # Aåˆ—: æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿æŒ
        existing_file_name = row[0] if len(row) > 0 and row[0] is not None else os.path.basename(file_path)
        new_row.append(existing_file_name)
        
        # Båˆ—: é …ç›®å€¤
        value_B = row[1] if len(row) > 1 else None
        new_row.append(value_B)
        
        # Cåˆ—ä»¥é™: æ„å‘³çš„ãƒãƒƒãƒ”ãƒ³ã‚°ã§ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®
        for header in master_headers:
            value = None
            if header in header_to_column:
                col_index = header_to_column[header]
                actual_index = col_index - 1  # 1-based ã‹ã‚‰ 0-based
                if 0 <= actual_index < len(row):
                    value = row[actual_index]
                    
                    # ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°: å•†å“ååˆ—ã«äººåãŒæ··å…¥ã—ã¦ã„ã‚‹å ´åˆã®ä¿®æ­£
                    file_name = os.path.basename(file_path)
                    if (file_name == "PAT0001_normalized.xlsx" and 
                        "å•†å“å" in header and value and 'æ²³ç€¨' in str(value)):
                        value = None  # å•†å“ååˆ—ã‹ã‚‰æ²³ç€¨é€ã‚’é™¤å»
            
            new_row.append(value)
        
        output_rows.append(new_row)

    return output_rows, master_headers



def process_phase5():

  municipality = os.environ.get("MUNICIPALITY_NAME")

  if not municipality:

    print("MUNICIPALITY_NAME ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    return



  base_dir = os.path.join(

    r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',

    municipality

  )

  if not os.path.exists(base_dir):

    print(f"æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")

    return



  print(f"MUNICIPALITY_NAME = {municipality}")

  print(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€: {base_dir}")



  # normalized.xlsx ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ï¼ˆé‡è¤‡æ­£è¦åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–ï¼‰
  files = [f for f in os.listdir(base_dir) 
           if f.startswith("PAT") and f.endswith("_normalized.xlsx") 
           and not f.endswith("_normalized_normalized.xlsx")]

  if not files:

    print("_normalized.xlsx ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

    return



  # ãƒã‚¹ã‚¿ãƒ¼é›†ç´„ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆï¼ˆall_collect.xlsxï¼‰

  master_wb = Workbook()

  master_ws = master_wb.active

  master_ws.title = "all_collect"

  # å›ºå®šãƒ˜ãƒƒãƒ€ãƒ¼ï¼šAåˆ—ï¼ãƒ•ã‚¡ã‚¤ãƒ«åã€Båˆ—ï¼é …ç›®

  master_ws.cell(row=1, column=1, value="ãƒ•ã‚¡ã‚¤ãƒ«å")

  master_ws.cell(row=1, column=2, value="é …ç›®")

  # master_headersï¼šCåˆ—ä»¥é™ã®é …ç›®ï¼ˆUnion ã—ãŸã™ã¹ã¦ã®ã‚½ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰

  master_headers = []

  master_data_rows = [] # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿è¡Œã‚’é›†ç´„



  for file in files:

    file_path = os.path.join(base_dir, file)

    try:

      rows, master_headers = process_file(file_path, master_headers)

      master_data_rows.extend(rows)

      print(f"å‡¦ç†å®Œäº†: {file}")

    except Exception as e:

      print(f"ã‚¨ãƒ©ãƒ¼: {file} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ â†’ {e}")



  # ãƒã‚¹ã‚¿ãƒ¼ã‚·ãƒ¼ãƒˆã®1è¡Œç›®ï¼ˆå›ºå®šãƒ˜ãƒƒãƒ€ãƒ¼ã«ç¶šãCåˆ—ä»¥é™ï¼‰ã« master_headers ã‚’è¨­å®š

  for i, header in enumerate(master_headers, start=3):

    master_ws.cell(row=1, column=i, value=header)



  # é›†ç´„ã—ãŸãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒã‚¹ã‚¿ãƒ¼ã‚·ãƒ¼ãƒˆã«æ›¸ãå‡ºã™ï¼ˆ2è¡Œç›®ä»¥é™ï¼‰

  current_row = 2

  for row in master_data_rows:

    for j, value in enumerate(row, start=1):

      master_ws.cell(row=current_row, column=j, value=value)

    current_row += 1



  all_collect_path = os.path.join(base_dir, "all_collect.xlsx")

  master_wb.save(all_collect_path)

  print(f"all_collect.xlsx ä½œæˆå®Œäº†: {all_collect_path}")

import os
import shutil

def process_phase7():
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€åï¼ˆMUNICIPALITY_NAMEï¼‰ã‚’å–å¾—
    municipality = os.environ.get("MUNICIPALITY_NAME")
    if not municipality:
        print("MUNICIPALITY_NAME ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    # Phase3 é…ä¸‹ã®å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
    source_dir = os.path.join(
        r'G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase3\HARV',
        municipality
    )
    source_file = os.path.join(source_dir, "all_collect.xlsx")
    
    if not os.path.exists(source_file):
        print(f"ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {source_file}")
        return

    # è¤‡è£½å…ˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
    dest_dir = r"G:\å…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–\â˜…OD\99_å•†å“ç®¡ç†\DATA\Phase4\HARV"
    if not os.path.exists(dest_dir):
        os.makedirs(dest_dir, exist_ok=True)
    
    # è¤‡è£½å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç’°å¢ƒå¤‰æ•°ã®å€¤ï¼ˆãƒ•ã‚©ãƒ«ãƒ€åï¼‰ã«å¤‰æ›´
    dest_file = os.path.join(dest_dir, f"{municipality}.xlsx")
    
    try:
        shutil.copy(source_file, dest_file)
        print(f"è¤‡è£½å®Œäº†: {dest_file}")
    except Exception as e:
        print(f"è¤‡è£½ã«å¤±æ•—ã—ã¾ã—ãŸ â†’ {e}")

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    process_phase1(TARGET_PATH, MUNICIPALITY_NAME, PHASE1_OUTPUT_DIR, LOG_FILE_PATH)
    process_phase2(MUNICIPALITY_NAME, PHASE1_OUTPUT_DIR, PHASE2_OUTPUT_DIR)
    process_phase3()
    process_phase4()
    process_phase5()
    process_phase7()

if __name__ == "__main__":
    main()
